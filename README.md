# **MoodTunes - Emotion-Based Music Recommendation App**



The **MoodTunes** project is an integrated emotion-based music recommendation system that combines frontend, backend, AI/ML models, and data analytics to provide personalized music recommendations based on user emotions. The application analyzes text, speech, or facial expressions and suggests music that aligns with the detected emotions.




<h2 id="-overview">üéµ Overview</h2>

MoodTunes provides personalized music recommendations based on users' emotional states detected through text, speech, and facial expressions. It interacts with a Django-based backend, AI/ML models for emotion detection, and utilizes data analytics for visual insights into emotion trends and model performance.




<h2 id="-technologies">üõ†Ô∏è Technologies</h2>

Here is the list of technologies used in the Moodify project:

### **Frontend**:
![React](https://img.shields.io/badge/React-61DAFB?style=for-the-badge&logo=react&logoColor=white)
![Axios](https://img.shields.io/badge/Axios-5A29E4?style=for-the-badge&logoColor=white)
![Material UI](https://img.shields.io/badge/MUI-007FFF?style=for-the-badge&logo=mui&logoColor=white)
![React Router](https://img.shields.io/badge/React%20Router-CA4245?style=for-the-badge&logo=react-router&logoColor=white)


### **Backend**:
![Django](https://img.shields.io/badge/Django-092E20?style=for-the-badge&logo=django&logoColor=white)
![Django REST Framework](https://img.shields.io/badge/DRF-ff1709?style=for-the-badge&logo=django&logoColor=white)
![MongoEngine](https://img.shields.io/badge/MongoEngine-47A248?style=for-the-badge&logo=mongodb&logoColor=white)
![JWT](https://img.shields.io/badge/JWT-000000?style=for-the-badge&logo=jsonwebtokens&logoColor=white)
![Spotify](https://img.shields.io/badge/Spotify-1DB954?style=for-the-badge&logo=spotify&logoColor=white)
![Swagger](https://img.shields.io/badge/Swagger-85EA2D?style=for-the-badge&logo=swagger&logoColor=black)
![Redoc](https://img.shields.io/badge/Redoc-EB222A?style=for-the-badge&logo=redoc&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)

### **Databases**:
![MongoDB](https://img.shields.io/badge/MongoDB-47A248?style=for-the-badge&logo=mongodb&logoColor=white)


### **AI/ML Models**:
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white)
![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD54F?style=for-the-badge&logo=huggingface&logoColor=black)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit%20Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)

<!-- 
### **Load Balancing**:
![NGINX](https://img.shields.io/badge/NGINX-009639?style=for-the-badge&logo=nginx&logoColor=white)
![Gunicorn](https://img.shields.io/badge/Gunicorn-499848?style=for-the-badge&logo=gunicorn&logoColor=white)

### **Data Analytics**:
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=matplotlib&logoColor=white)
![Hadoop](https://img.shields.io/badge/Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black)
![Spark](https://img.shields.io/badge/Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)

### **Mobile (in progress)**:
![React Native](https://img.shields.io/badge/React%20Native-61DAFB?style=for-the-badge&logo=react&logoColor=white)
![Expo](https://img.shields.io/badge/Expo-000020?style=for-the-badge&logo=expo&logoColor=white)
![Expo Go](https://img.shields.io/badge/Expo%20Go-000020?style=for-the-badge&logo=expo&logoColor=white)

### **Containerization, Deployment, and CI/CD**:
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)
![Jenkins](https://img.shields.io/badge/Jenkins-D24939?style=for-the-badge&logo=jenkins&logoColor=white)
![Render](https://img.shields.io/badge/Render-46E3B7?style=for-the-badge&logo=render&logoColor=black)
![Vercel](https://img.shields.io/badge/Vercel-000000?style=for-the-badge&logo=vercel&logoColor=white) -->

<h2 id="-user-interface">üñºÔ∏è User Interface</h2>

### Landing Page

<p align="center">
  <img src="images/landlight.png" alt="Landing Page" width="100%" style="border-radius: 10px">
</p>

### Landing Page - Dark Mode

<p align="center">
  <img src="images/landingdark.png" alt="Landing Page - Dark Mode" width="100%" style="border-radius: 10px">
</p>

### Home Page

<p align="center">
  <img src="images/homi.png" alt="Home Page" width="100%" style="border-radius: 10px">
</p>

<!-- #### Home Page - Dark Mode

<p align="center">
  <img src="images/homepage-dark.png" alt="Home Page - Dark Mode" width="100%" style="border-radius: 10px">
</p> -->

#### Text Input

<p align="center">
  <img src="images/textinp.png" alt="Text Input" width="100%" style="border-radius: 10px">
</p>

<!-- #### Text Input - Dark Mode

<p align="center">
  <img src="images/textinput-dark.png" alt="Text Input - Dark Mode" width="100%" style="border-radius: 10px">
</p> -->

#### Speech Input

<p align="center">
  <img src="images/speech.png" alt="Speech Input" width="100%" style="border-radius: 10px">
</p>

<p align="center">
  <img src="images/speechinp.png" alt="Speech Input" width="100%" style="border-radius: 10px">
</p>

<!-- #### Speech Input - Dark Mode

<p align="center">
  <img src="images/speechinputmodal-dark.png" alt="Speech Input - Dark Mode" width="100%" style="border-radius: 10px">
</p> -->

#### Facial Expression Input

<p align="center">
  <img src="images/face.png" alt="Facial Input" width="100%" style="border-radius: 10px">
</p>

<p align="center">
  <img src="images/faceinp.png" alt="Facial Input" width="100%" style="border-radius: 10px">
</p>

 #### Facial Expression Input - Dark Mode

<p align="center">
  <img src="images/facedark.png" alt="Facial Input - Dark Mode" width="100%" style="border-radius: 10px">
</p> 

### Profile Page

<p align="center">
  <img src="images/prof.png" alt="Profile Page" width="100%" style="border-radius: 10px">
</p>



#### Profile Page - Dark Mode

<p align="center">
  <img src="images/profiledark.png" alt="Profile Page - Dark Mode" width="100%" style="border-radius: 10px">
</p>

#### Profile Page (Continued)

<p align="center">
  <img src="images/prof2.png" alt="Profile Page" width="100%" style="border-radius: 10px">
</p>
### Results - Recommendations Page

<p align="center">
  <img src="images/reccomd.png" alt="Results Page" width="100%" style="border-radius: 10px">
</p>

<!-- #### Results - Recommendations Page - Dark Mode

<p align="center">
  <img src="images/results-dark.png" alt="Results Page - Dark Mode" width="100%" style="border-radius: 10px">
</p> -->

### Login Page

<p align="center">
  <img src="images/login1.png" alt="Login Page" width="100%" style="border-radius: 10px">
</p>

#### Login Page - Dark Mode

<p align="center">
  <img src="images/logindark.png" alt="Login Page - Dark Mode" width="100%" style="border-radius: 10px">
</p>

### Registration Page

<p align="center">
  <img src="images/register1.png" alt="Registration Page" width="100%" style="border-radius: 10px">
</p>

<!-- #### Registration Page - Dark Mode

<p align="center">
  <img src="images/register-dark.png" alt="Registration Page - Dark Mode" width="100%" style="border-radius: 10px">
</p> -->











### **AI/ML Models Overview**

The AI/ML models are built using PyTorch, TensorFlow, Keras, and HuggingFace Transformers. These models are trained on various datasets to detect emotions from text, speech, and facial expressions.

The emotion detection models are used to analyze user inputs and provide real-time music recommendations based on the detected emotions. The models are trained on various datasets to capture the nuances of human emotions and provide accurate predictions.

- **Text Emotion Detection**: Detects emotions from text inputs.
- **Speech Emotion Detection**: Analyzes emotions from speech inputs.
- **Facial Emotion Detection**: Detects emotions from facial expressions.

The models are integrated into the backend API services to provide real-time emotion detection and music recommendations for users.







